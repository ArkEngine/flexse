(1) 实时索引
    -a- 更新之后即可查询到数据，就像mysql一样，insert之后马上可以select出来
        - 测试方案: 插入一条消息，搜索消息中的某个term
    -b- 崩溃恢复需要和消息一起配合完成，当更新过程中崩溃时，会让消息队列从断点处回放，消息一个不少。
        - 测试方案: 插入一条消息，能够搜索出，重启程序，发现数据已经回放成功，又可以搜索到
        - 测试方案: 数据持久化之后，观察flexse是否重设断点，重启程序后，无需回放。
    -c- 能够平滑处理长时间大压力插入数据的情况(如数据重做)
        - 测试方案: 长时间大压力插入数据，观察是否因为持久化时间太长而阻塞更新
        - 测试方案: 长时间大压力插入数据，观察当day数据持久化超过120s后，下次是否会持久化到day/2目录
        - 测试方案: 长时间大压力插入数据，设置dump间隔(如5分钟)，观察内存索引是否能定时dump
        - 测试方案: 长时间大压力插入数据，设置dump间隔很长(如1小时)，观察当内存索引满了时是否会自动持久化
        - 测试方案: 长时间大压力插入数据，数据特点是存在某些term的拉链特别长，观察内存索引的内存合并是否正常
        - 测试方案: 长时间大压力插入数据，是否能搜索到插入的数据(这个我已经用精确的测试方案测试通过了)
        - 测试方案: 长时间大压力插入数据，并发搜索。
(2) 更新配置及测试方案
    -a- 插入操作，其流程主要是把数据传入插件中的更新函数，然后得到外部doc_id/term数组/attr数组，然后更新attr，
        如果term数组不为空，则需要分配内部id并更新索引，否则直接返回即可。
        - 测试方案: 先插入一个含有属性的文档(比如视频的播放数)，然后检索出该文档，观察文档属性是否正确
        - 测试方案: 修改标题，继续插入该文档，再次检索，观察是否去掉失效的文档
        - 测试方案: 修改属性，继续插入该文档，再次检索，观察属性值是否更新正确
        - 测试方案: 修改属性，去掉其他更新参数(与分词相关的)，更新之，观察是否需要分配内部id(不需要)
        - 测试方案: [插件相关] DOC_ID处理方式，更新数据中，必须含有DOC_ID对应的字段，否则失败
        - 测试方案: [插件相关] NLP处理方式，更新数据中，这部分数据将做分词处理(详细策略详见配置说明)
        - 测试方案: [插件相关] LIST_STR处理方式，更新数据中，这部分数据将做前缀处理
        - 测试方案: [插件相关] LIST_INT处理方式，更新数据中，这部分数据将做前缀处理
        - 测试方案: [插件相关] STR处理方式，更新数据中，这部分数据将做前缀处理
        - 测试方案: [插件相关] INT处理方式，更新数据中，这部分数据将做前缀处理
    -b- 删除操作
        - 测试方案: 删除一个文档，检测是否还能搜索到
        - 测试方案: 删除一组文档，检测是否还能搜索到
    -c- 恢复操作
        - 测试方案: 恢复(反删除)一个文档，检测是否还能搜索到
        - 测试方案: 恢复(反删除)一组文档，检测是否还能搜索到
(3) 查询语法
    -a- 查询语法格式
        {
            "offset"  : 0,     // 默认为0
            "size"    : 2000,  // 默认为2000, offset, size相当于mysql中的limit操作
            "orderby" : "somefield", // 按照某个field排序，降序排列
            "termlist":
            [
                ["term" : "a", "weight": 50, "synonyms": ["A", "A'"]], // a有两个同义词A和A'
                ["term" : "b", "weight": 30, "synonyms": ["B"]]        // b有一个同义词B
                ["term" : "c", "weight": 20]                           // 木有同义词
            ]
        }
    -b- 通用排序算法
        - 测试方案: 变换查询语法中的orderby字段，观察是否按照规定字段排序(有demo的)
    -c- 通用计数算法
        - 测试方案: 变换查询语法中的groupby字段，观察聚类输出(算法已经实现，查询语法中暂未实现)
    -d- 通用过滤算法
        - 测试方案: 设置查询语法中的filterlist字段，观察结果输出(算法已经实现，查询语法中暂未实现)
    -e- 通用调权算法
        - 测试方案: 设置查询语法中的rankinglist字段，观察结果输出(算法已经实现，查询语法中暂未实现)
----------------------------
--      更新配置说明      --
----------------------------
{
    "GENERAL":
    {
        "MaxOuterID"   :1000000,   // 最大支持的外部ID大小
        "MaxInnerID"   :2000000,   // 最大支持分配的内部ID大小，如果对已经存在的修改频繁
        "IdmapDataDir" :"./data/idmap/"
    },
    "term_idf_dict_path" : "./data/nlp/idf_ku6_manual_int.tch",
    "ATTR":
    {
        "AttrDataDir" : "./data/attr/"
    },
    "DETAIL":
    {
        "DetailDataDir" : "./data/detail/"
    },
    "INDEXCONFIG":
    {
        "PostingBucketSize"      : 20,     // N begin 20 and 24, bucket_size = 1<<N
        "PostingHeadListSize"    : 20000,  // default as 2000000,
        "PostingMemBlockNumList" : [40000, 20000]
    },
    "FLEXINDEX":
    [
        // DOC_ID表示作外部ID处理，"field":"id"写入posting_list_cell中的'id'字段
        {"vid"       : {"op":"DOC_ID", "field":"id"}},
        // NLP表示作分词处理，
        // 'hit_field'表示在posting_list_cell的'title_hit'字段标记为1，表示该term来自标题，
        // 'hit_weight':5表示在term的文本权重中加5
        // 'position':1表示记住该字段切词后的term位置，ranking时，可以选择对该字段执行offset算法
        {"title"     : {"op":"NLP", "hit_field":"title_hit", "hit_weight":5, "position":1}},
        // "optional":1表示这个字段是可选的，不在更新数据中出现亦可，如果不指定optional，则表示必须含有这些字段
        {"anchor"    : {"op":"NLP", "hit_field":"anchor_hit", "hit_weight":3, "optional":1}},
        // 'content'仅作分词处理即可
        {"content"   : {"op":"NLP"},
        // LIST_STR表示把tags所对应的数组中的每个字符串做前缀处理(加上TAG^)
        {"tags"      : {"op":"LIST_STR", "token":"TAG^"}},
        // INT表示把type所对应的整形做前缀处理(加上TYPE^)
        {"type"      : {"op":"LIST_STR", "token":"TYPE^"}}
    ],
    "STRUCTMASK":
    {
        // 以下配置一旦改变就需要重做数据 
        // 倒排索引部分的数据考虑固定化
        "posting_list_cell":
        [
            {"id"            : 26}, // 最多支持的外部ID，可以使用MaxOuterID约束
            {"title_hit"     :  1}, // 当在title的field中出现时，设置为1
            {"anchor_hit"    :  1}, // 当在anchor的field中出现时，设置为1
            {"tag_hit"       :  1}, // 当在tag的field中出现时，设置为1
            {"hit_count"     :  3}, // 在文档中出现次数
            {"tf"            :  4},
            {"idf"           :  4},
            {"weight"        :  8}, // 文本的基础权重
            {"offset1"       :  8}  // offset位置1
            {"offset2"       :  8}  // offset位置2
        ],
        "document_attribute":
        [
            // 如果更新的json对象中，含有下面的field且为整形，则更新这些属性
            // 如果操作这些整形时，超过了其最大值，则设为最大值
            // 比如8bit最大值为255，如果更新值超过，则设为最大值255
            {"vid"           : 32}, // 视频的vid
            {"wth_num"       : 32}, // 播放数
            {"cmt_num"       : 32}, // 评论数
            {"duration"      : 32}, // 时间长度
            {"vsign1"        : 32}, // 视频签名1
            {"vsign2"        : 32}  // 视频签名2
        ] 
    }
}
---------------------------
